{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import benepar, spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# benepar.download('benepar_en3')\n",
    "# benepar.download('benepar_de2')\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !python -m spacy download de_core_news_md\n",
    "# !python -m spacy download de_dep_news_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (NP (DT The) (NN time)) (PP (IN for) (NP (NN action)))) (VP (VBZ is) (ADVP (RB now))) (. .))\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "if spacy.__version__.startswith('2'):\n",
    "    nlp.add_pipe(benepar.BeneparComponent(\"benepar_en3\"))\n",
    "else:\n",
    "    nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\n",
    "\n",
    "doc = nlp(\"The time for action is now. It's never too late to do something.\")\n",
    "sent = list(doc.sents)[0]\n",
    "print(sent._.parse_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (ADV Sicherlich) (VAFIN ist) (PPER es) (PTKNEG nicht) (AP (PTKA zu) (ADJD spät))) ($, ,) (VP (PIS etwas) (VZ (PTKZU zu) (VVINF tun))) ($. .)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('de_core_news_md')\n",
    "if spacy.__version__.startswith('2'):\n",
    "    nlp.add_pipe(benepar.BeneparComponent(\"benepar_de2\"))\n",
    "else:\n",
    "    nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_de2\"})\n",
    "\n",
    "doc = nlp(\"Sicherlich ist es nicht zu spät, etwas zu tun. Die Zeit für Aktionen ist jetzt.\")\n",
    "sent = list(doc.sents)[0]\n",
    "print(sent._.parse_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"378fd357eeed4b95a5d7e65623a55ab5-0\" class=\"displacy\" width=\"2675\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Sicherlich</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">ist</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">es</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">nicht</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">zu</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">spät,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">etwas</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">zu</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">tun.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">Die</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">Zeit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">für</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">Aktionen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2325\">ist</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2325\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2500\">jetzt.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2500\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-1\" stroke-width=\"2px\" d=\"M245,352.0 C245,264.5 385.0,264.5 385.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M385.0,354.0 L393.0,342.0 377.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-2\" stroke-width=\"2px\" d=\"M245,352.0 C245,177.0 565.0,177.0 565.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ng</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M565.0,354.0 L573.0,342.0 557.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-4\" stroke-width=\"2px\" d=\"M245,352.0 C245,89.5 920.0,89.5 920.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pd</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,354.0 L928.0,342.0 912.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,177.0 1440.0,177.0 1440.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oa</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pm</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-7\" stroke-width=\"2px\" d=\"M420,352.0 C420,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">re</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-9\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,177.0 2315.0,177.0 2315.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1820,354.0 L1812,342.0 1828,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-10\" stroke-width=\"2px\" d=\"M1820,352.0 C1820,264.5 1960.0,264.5 1960.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mnr</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1960.0,354.0 L1968.0,342.0 1952.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-11\" stroke-width=\"2px\" d=\"M1995,352.0 C1995,264.5 2135.0,264.5 2135.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2135.0,354.0 L2143.0,342.0 2127.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-378fd357eeed4b95a5d7e65623a55ab5-0-12\" stroke-width=\"2px\" d=\"M2345,352.0 C2345,264.5 2485.0,264.5 2485.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-378fd357eeed4b95a5d7e65623a55ab5-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2485.0,354.0 L2493.0,342.0 2477.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spacy.displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands on our real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent-id</th>\n",
       "      <th>topic</th>\n",
       "      <th>phrase</th>\n",
       "      <th>phrase_number</th>\n",
       "      <th>genre</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>user</th>\n",
       "      <th>phrase_tokenized</th>\n",
       "      <th>num_statements</th>\n",
       "      <th>statement_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>989</td>\n",
       "      <td>alchemie</td>\n",
       "      <td>Eine sehr bekannte Alchemisten war Maria die J...</td>\n",
       "      <td>2_long</td>\n",
       "      <td>Wissenschaft|Seiten_mit_defekten_Dateilinks</td>\n",
       "      <td>2022-10-03T06:15:06Z</td>\n",
       "      <td>48f66906899cc4a9477b6c9e32ff4424</td>\n",
       "      <td>0:=Eine 1:=sehr 2:=bekannte 3:=Alchemisten 4:=...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>990</td>\n",
       "      <td>alchemie</td>\n",
       "      <td>Alchemisten wollen etwas ver-bessern.</td>\n",
       "      <td>3_long</td>\n",
       "      <td>Wissenschaft|Seiten_mit_defekten_Dateilinks</td>\n",
       "      <td>2022-10-03T06:15:06Z</td>\n",
       "      <td>48f66906899cc4a9477b6c9e32ff4424</td>\n",
       "      <td>0:=Alchemisten 1:=wollen 2:=etwas 3:=ver-bessern.</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>991</td>\n",
       "      <td>alchemie</td>\n",
       "      <td>Zum Beispiel, \\newline wollen sie kranke Mensc...</td>\n",
       "      <td>4_long</td>\n",
       "      <td>Wissenschaft|Seiten_mit_defekten_Dateilinks</td>\n",
       "      <td>2022-10-03T06:15:06Z</td>\n",
       "      <td>48f66906899cc4a9477b6c9e32ff4424</td>\n",
       "      <td>0:=Zum 1:=Beispiel, 2:=\\newline 3:=wollen 4:=s...</td>\n",
       "      <td>2</td>\n",
       "      <td>[[3, 4], [5, 6, 7, 8]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>992</td>\n",
       "      <td>alchemie</td>\n",
       "      <td>Alchemisten haben Athanoren benutzt.</td>\n",
       "      <td>5_long</td>\n",
       "      <td>Wissenschaft|Seiten_mit_defekten_Dateilinks</td>\n",
       "      <td>2022-10-03T06:15:06Z</td>\n",
       "      <td>48f66906899cc4a9477b6c9e32ff4424</td>\n",
       "      <td>0:=Alchemisten 1:=haben 2:=Athanoren 3:=benutzt.</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>993</td>\n",
       "      <td>alchemie</td>\n",
       "      <td>Sue haben Schwarz-pulver erfunden.</td>\n",
       "      <td>6_long</td>\n",
       "      <td>Wissenschaft|Seiten_mit_defekten_Dateilinks</td>\n",
       "      <td>2022-10-03T06:15:06Z</td>\n",
       "      <td>48f66906899cc4a9477b6c9e32ff4424</td>\n",
       "      <td>0:=Sue 1:=haben 2:=Schwarz-pulver 3:=erfunden.</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sent-id     topic                                             phrase  \\\n",
       "0      989  alchemie  Eine sehr bekannte Alchemisten war Maria die J...   \n",
       "1      990  alchemie              Alchemisten wollen etwas ver-bessern.   \n",
       "2      991  alchemie  Zum Beispiel, \\newline wollen sie kranke Mensc...   \n",
       "3      992  alchemie               Alchemisten haben Athanoren benutzt.   \n",
       "4      993  alchemie                 Sue haben Schwarz-pulver erfunden.   \n",
       "\n",
       "  phrase_number                                        genre  \\\n",
       "0        2_long  Wissenschaft|Seiten_mit_defekten_Dateilinks   \n",
       "1        3_long  Wissenschaft|Seiten_mit_defekten_Dateilinks   \n",
       "2        4_long  Wissenschaft|Seiten_mit_defekten_Dateilinks   \n",
       "3        5_long  Wissenschaft|Seiten_mit_defekten_Dateilinks   \n",
       "4        6_long  Wissenschaft|Seiten_mit_defekten_Dateilinks   \n",
       "\n",
       "              timestamp                              user  \\\n",
       "0  2022-10-03T06:15:06Z  48f66906899cc4a9477b6c9e32ff4424   \n",
       "1  2022-10-03T06:15:06Z  48f66906899cc4a9477b6c9e32ff4424   \n",
       "2  2022-10-03T06:15:06Z  48f66906899cc4a9477b6c9e32ff4424   \n",
       "3  2022-10-03T06:15:06Z  48f66906899cc4a9477b6c9e32ff4424   \n",
       "4  2022-10-03T06:15:06Z  48f66906899cc4a9477b6c9e32ff4424   \n",
       "\n",
       "                                    phrase_tokenized  num_statements  \\\n",
       "0  0:=Eine 1:=sehr 2:=bekannte 3:=Alchemisten 4:=...               1   \n",
       "1  0:=Alchemisten 1:=wollen 2:=etwas 3:=ver-bessern.               1   \n",
       "2  0:=Zum 1:=Beispiel, 2:=\\newline 3:=wollen 4:=s...               2   \n",
       "3   0:=Alchemisten 1:=haben 2:=Athanoren 3:=benutzt.               1   \n",
       "4     0:=Sue 1:=haben 2:=Schwarz-pulver 3:=erfunden.               1   \n",
       "\n",
       "         statement_spans   \n",
       "0                     NaN  \n",
       "1                     NaN  \n",
       "2  [[3, 4], [5, 6, 7, 8]]  \n",
       "3                     NaN  \n",
       "4                     NaN  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in ../data/train_all_3k.csv\n",
    "df = pd.read_csv('../data/train_updated.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up Benepar model to spaCY pipeline\n",
    "nlp = spacy.load('de_dep_news_trf')\n",
    "\n",
    "if spacy.__version__.startswith('2'):\n",
    "    nlp.add_pipe(benepar.BeneparComponent(\"benepar_de2\"))\n",
    "else:\n",
    "    nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_de2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sent_w_spacy(nlp, sent):\n",
    "\n",
    "    doc = nlp(sent)\n",
    "    sent = list(doc.sents)[0]\n",
    "    toks = [token.text for token in doc]\n",
    "\n",
    "    if \"(S \" in sent._.parse_string and \"(V\" in sent._.parse_string:\n",
    "        is_sent = True\n",
    "    elif len(toks) < 3:\n",
    "        is_sent = True\n",
    "    else:\n",
    "        is_sent = False\n",
    "\n",
    "    return sent._.parse_string, is_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (ADV Hier) (VAFIN ist) (NP (ART ein) (ADJA gutes) (NN Beispiel) (PP (APPR für) (ART einen) (ADJA einfachen) (NN Satz)))) True\n"
     ]
    }
   ],
   "source": [
    "sent = \"Hier ist ein gutes Beispiel für einen einfachen Satz\"\n",
    "\n",
    "tree_as_string, is_sent = parse_sent_w_spacy(nlp, sent)\n",
    "print(tree_as_string, is_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP (ART Eine) (AP (ADV sehr) (ADJA bekannte)) (NN Alchemisten)) (VAFIN war) (PN (NE Maria) (NP (ART die) (NN Jüdin)))) ($. .) True\n",
      "(S (NN Alchemisten) (VMFIN wollen) (VP (PIS etwas) (VVINF ver-bessern))) ($. .) True\n",
      "(PP (APPRART Zum) (NN Beispiel)) ($, ,) (S (ADV \\newline) (VMFIN wollen) (PPER sie) (VP (NP (ADJA kranke) (NN Menschen)) (ADJD gesund) (VVINF machen))) ($. .) True\n",
      "(S (NN Alchemisten) (VAFIN haben) (VP (NN Athanoren) (VVPP benutzt))) ($. .) True\n",
      "(S (NE Sue) (VAFIN haben) (VP (NN Schwarz-pulver) (VVPP erfunden))) ($. .) True\n",
      "(S (KON Und) (PPER sie) (VAFIN haben) (VP (NN Porzellan) (VVPP erfunden))) ($. .) True\n",
      "(S (NN Alchemie) (VAFIN ist) (NP (ART ein) (ADJA arabisches) (NN Wort))) ($. .) True\n",
      "(S (NN Alchemie) (VAFIN ist) (NN Chemie)) ($. .) True\n",
      "(S (NP (PPER Es)) (VAFIN werden) (CNP (NN Versuche) (KON und) (NN Experimente)) (VVPP gemacht)) ($. .) True\n",
      "(S (KOUS Damit) (PIS man) (VVFIN versteht) (S (PWAV wie) (PIS etwas) (VVFIN funktioniert))) ($. .) True\n"
     ]
    }
   ],
   "source": [
    "for sent in df[\"phrase\"][0:10]:\n",
    "    tree_as_string, is_sent = parse_sent_w_spacy(nlp, sent)\n",
    "    print(tree_as_string, is_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2944/2944 [08:25<00:00,  5.83it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for sent in tqdm(df[\"phrase\"]):\n",
    "    tree_as_string, is_sent = parse_sent_w_spacy(nlp, sent)\n",
    "    results.append((sent, tree_as_string, is_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert ls to DataFrame and save to ../data/bracket_is_sent_results.csv\n",
    "df_results = pd.DataFrame(results, columns=[\"sentence\", \"tree\", \"is_sent\"])\n",
    "df_results.to_csv('../data/bracket_is_sent_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9194972826086957\n",
      "     0     1\n",
      "0  303   146\n",
      "1   91  2404\n"
     ]
    }
   ],
   "source": [
    "gold = []\n",
    "for num_statements in df[\"num_statements\"]:\n",
    "    if num_statements == 0:\n",
    "        gold.append(False)\n",
    "    else:\n",
    "        gold.append(True)\n",
    "\n",
    "pred = pd.read_csv('../data/bracket_is_sent_results.csv')[\"is_sent\"]\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = accuracy_score(gold, pred)\n",
    "# create a DataFrame from the confusion matrix\n",
    "cm = confusion_matrix(gold, pred)\n",
    "cm_df = pd.DataFrame(cm)\n",
    "\n",
    "print(accuracy)\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = benepar.Parser(\"benepar_de2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentence(df, sent_idx):\n",
    "    # extract pre-tokenizes sentence\n",
    "    sent_toks = df['phrase_tokenized'][sent_idx].split()\n",
    "    sent_toks = [s.split(':=')[1] for s in sent_toks]\n",
    "            \n",
    "    # parse the sentence\n",
    "    result = parser.parse(sent_toks)\n",
    "\n",
    "    # some extra gold information\n",
    "    tokens = df['phrase_tokenized'][sent_idx]\n",
    "    statement_spans = df['statement_spans '][sent_idx]\n",
    "\n",
    "    return result, tokens, statement_spans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP\n",
      "  (NP (ART Eine) (AP (ADV sehr) (ADJA bekannte)) (NN Alchemisten))\n",
      "  (VAFIN war)\n",
      "  (NE Maria)\n",
      "  (ART die)\n",
      "  ($. Jüdin.))\n",
      "0:=Eine 1:=sehr 2:=bekannte 3:=Alchemisten 4:=war 5:=Maria 6:=die 7:=Jüdin.\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "result0, tokens0, statement_spans0 = parse_sentence(df, 0)\n",
    "\n",
    "print(result0)\n",
    "print(tokens0)\n",
    "print(statement_spans0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP\n",
      "  (APPRART Zum)\n",
      "  ($, Beispiel,)\n",
      "  (ADV \\newline)\n",
      "  (VMFIN wollen)\n",
      "  (PPER sie)\n",
      "  (NP (ADJA kranke) (NN Menschen))\n",
      "  (ADJD gesund)\n",
      "  ($. machen.))\n",
      "0:=Zum 1:=Beispiel, 2:=\\newline 3:=wollen 4:=sie 5:=kranke 6:=Menschen 7:=gesund 8:=machen.\n",
      "[[3, 4], [5, 6, 7, 8]]\n"
     ]
    }
   ],
   "source": [
    "result2, tokens2, statement_spans2 = parse_sentence(df, 2)\n",
    "\n",
    "print(result2)\n",
    "print(tokens2)\n",
    "print(statement_spans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TOP\n",
      "  (S\n",
      "    (ADV Hier)\n",
      "    (VAFIN ist)\n",
      "    (NP\n",
      "      (ART ein)\n",
      "      (ADJA gutes)\n",
      "      (NN Beispiel)\n",
      "      (PP (APPR für) (ART einen) (ADJA einfachen) (NN Satz)))))\n"
     ]
    }
   ],
   "source": [
    "sent_toks = [\n",
    "    \"Hier\",\n",
    "    \"ist\",\n",
    "    \"ein\",\n",
    "    \"gutes\",\n",
    "    \"Beispiel\",\n",
    "    \"für\",\n",
    "    \"einen\",\n",
    "    \"einfachen\",\n",
    "    \"Satz\"\n",
    " ]\n",
    "        \n",
    "# parse the sentence\n",
    "result = parser.parse(sent_toks)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zum',\n",
       " 'Beispiel,',\n",
       " '\\\\newline',\n",
       " 'wollen',\n",
       " 'sie',\n",
       " 'kranke',\n",
       " 'Menschen',\n",
       " 'gesund',\n",
       " 'machen.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.split(':=')[1] for s in df['phrase_tokenized'][2].split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alkopos\n",
      "Flaschen\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import Tree\n",
    "\n",
    "def extract_nps(tagged_sentence):\n",
    "    tree = Tree.fromstring(tagged_sentence)\n",
    "    nps = []\n",
    "    \n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() == 'NN':\n",
    "            np_words = subtree.leaves()\n",
    "            np_string = ' '.join(np_words)\n",
    "            nps.append(np_string)\n",
    "    \n",
    "    return nps\n",
    "\n",
    "# Example usage\n",
    "tagged_sentence = \"(TOP (S (ADV Meistens) (VAFIN werden) (NN Alkopos) (PP (APPR in) (ADJA bunten) (NN Flaschen))) ($. verkauft.))\"\n",
    "nps = extract_nps(tagged_sentence)\n",
    "for np in nps:\n",
    "    print(np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: bunte Flasche, Size: 2\n",
      "NN: Flaschen, Size: 1\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import Tree\n",
    "\n",
    "def extract_nouns_with_sizes(tagged_sentence):\n",
    "    tree = Tree.fromstring(tagged_sentence)\n",
    "    nouns_with_sizes = []\n",
    "    \n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() in {'NN', 'NNS', 'NNP', 'NNPS'}:\n",
    "            noun_words = subtree.leaves()\n",
    "            noun_size = len(noun_words)\n",
    "            noun_string = ' '.join(noun_words)\n",
    "            nouns_with_sizes.append((noun_string, noun_size))\n",
    "    \n",
    "    return nouns_with_sizes\n",
    "\n",
    "# Example usage\n",
    "tagged_sentence = \"(TOP (S (ADV Meistens) (VAFIN werden) (NN (ADJ bunte) Flasche) (PP (APPR in) (ADJA bunten) (NN Flaschen))) ($. verkauft.))\"\n",
    "nouns_with_sizes = extract_nouns_with_sizes(tagged_sentence)\n",
    "for noun, size in nouns_with_sizes:\n",
    "    print(f\"NN: {noun}, Size: {size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NN: Meistens werden bunte Flasche in bunten Flaschen verkauft., Size: 8\n",
      "NN: Meistens werden bunte Flasche in bunten Flaschen, Size: 7\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import Tree\n",
    "\n",
    "def extract_nouns_with_sizes(tagged_sentence):\n",
    "    tree = Tree.fromstring(tagged_sentence)\n",
    "    nouns_with_sizes = []\n",
    "    \n",
    "    for subtree in tree.subtrees():\n",
    "        if subtree.label() in {'S', 'TOP'}:\n",
    "            noun_words = subtree.leaves()\n",
    "            noun_size = len(noun_words)\n",
    "            noun_string = ' '.join(noun_words)\n",
    "            nouns_with_sizes.append((noun_string, noun_size))\n",
    "    \n",
    "    return nouns_with_sizes\n",
    "\n",
    "# Example usage\n",
    "tagged_sentence = \"(TOP (S (ADV Meistens) (VAFIN werden) (NN (ADJ bunte) Flasche) (PP (APPR in) (ADJA bunten) (NN Flaschen))) ($. verkauft.))\"\n",
    "nouns_with_sizes = extract_nouns_with_sizes(tagged_sentence)\n",
    "for noun, size in nouns_with_sizes:\n",
    "    print(f\"NN: {noun}, Size: {size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ez2Read",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
